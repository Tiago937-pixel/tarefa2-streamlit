# Dashboard de An√°lise de Pre√ßos Imobili√°rios - Ames Housing Dataset
# Tarefa 2: Precifica√ß√£o Imobili√°ria com ANOVA e Regress√£o Linear
# Professor: Jo√£o Gabriel de Moraes Souza
# UnB - Departamento de Engenharia de Produ√ß√£o

import streamlit as st
import pandas as pd
import numpy as np
import scipy.stats as stats
import statsmodels.api as sm
from statsmodels.formula.api import ols
from statsmodels.stats.multicomp import pairwise_tukeyhsd
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.stats.diagnostic import het_breuschpagan
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import os
from sklearn.metrics import mean_squared_error, mean_absolute_error

# --- Configura√ß√£o da P√°gina ---
st.set_page_config(
    layout="wide", 
    page_title="An√°lise Imobili√°ria - Ames Housing",
    page_icon="üè†"
)

# CSS personalizado inspirado nos dashboards do professor
st.markdown("""
<style>
.stSlider > div > div > div > div > div > div {
    background-color: #4CAF50 !important;
}
.main-header {
    text-align: center;
    color: #003366;
    padding: 1rem 0;
}
.metric-container {
    background-color: #f0f2f6;
    padding: 1rem;
    border-radius: 0.5rem;
    margin: 0.5rem 0;
}
</style>
""", unsafe_allow_html=True)

# --- Cabe√ßalho Principal ---
st.markdown("<h1 class='main-header'>üè† Dashboard de An√°lise de Pre√ßos Imobili√°rios</h1>", unsafe_allow_html=True)
st.markdown("<h3 class='main-header'>Ames Housing Dataset - ANOVA e Regress√£o Linear</h3>", unsafe_allow_html=True)
st.markdown("<p class='main-header'>Professor: Jo√£o Gabriel de Moraes Souza</p>", unsafe_allow_html=True)
st.markdown("---")

# --- Fun√ß√£o de carregamento de dados ---
@st.cache_data
def load_data():
    """
    Carrega e trata o dataset Ames Housing
    """
    local_csv = "AmesHousing.csv"
    
    if not os.path.isfile(local_csv):
        st.error(f"‚ùå Arquivo n√£o encontrado: {local_csv}")
        st.info("üí° Coloque o arquivo 'AmesHousing.csv' na raiz do projeto.")
        return pd.DataFrame()

    try:
        df = pd.read_csv(local_csv)
        
        # Tratamento de valores ausentes
        for col in df.select_dtypes(include=np.number).columns:
            if df[col].isnull().any():
                df[col].fillna(df[col].median(), inplace=True)
        
        for col in df.select_dtypes(include='object').columns:
            if df[col].isnull().any():
                df[col].fillna('Missing', inplace=True)

        # Renomea√ß√£o de colunas para facilitar uso
        column_mapping = {
            'Overall Qual': 'OverallQual',
            'Gr Liv Area': 'GrLivArea',
            'Total Bsmt SF': 'TotalBsmtSF',
            '1st Flr SF': 'FirstFlrSF',
            'Bsmt Qual': 'BsmtQual',
            'Kitchen Qual': 'KitchenQual',
            'Fireplace Qu': 'FireplaceQu',
            'Garage Type': 'GarageType',
            'Garage Cars': 'GarageCars',
            'Garage Area': 'GarageArea',
            'Central Air': 'CentralAir',
            'MS Zoning': 'MSZoning',
            'House Style': 'HouseStyle',
            'Exter Qual': 'ExterQual'
        }
        df.rename(columns=column_mapping, inplace=True, errors='ignore')
        
        st.success("‚úÖ Dataset Ames Housing carregado com sucesso!")
        return df
        
    except Exception as e:
        st.error(f"‚ùå Erro ao carregar dados: {e}")
        return pd.DataFrame()

# Carregamento dos dados
df_ames = load_data()

if df_ames.empty:
    st.warning("‚ö†Ô∏è Dataset n√£o carregado. Funcionalidades limitadas.")
    st.stop()

# --- Barra Lateral ---
st.sidebar.title("üõ†Ô∏è Configura√ß√µes de An√°lise")
st.sidebar.markdown("### Selecione o tipo de an√°lise:")

analysis_type = st.sidebar.selectbox(
    "Escolha a An√°lise:",
    ["üìä Vis√£o Geral dos Dados", "üî¨ An√°lise ANOVA", "üìà Regress√£o Linear"]
)

# Par√¢metros globais
alpha_global = st.sidebar.slider("N√≠vel de signific√¢ncia (Œ±)", 0.01, 0.10, 0.05, 0.01)

# --- Se√ß√£o 1: Vis√£o Geral dos Dados ---
if analysis_type == "üìä Vis√£o Geral dos Dados":
    st.header("üìä Vis√£o Geral dos Dados")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üìã Observa√ß√µes", f"{df_ames.shape[0]:,}")
    with col2:
        st.metric("üìä Vari√°veis", f"{df_ames.shape[1]}")
    with col3:
        if 'SalePrice' in df_ames.columns:
            st.metric("üí∞ Pre√ßo M√©dio", f"${df_ames['SalePrice'].mean():,.0f}")
    
    # Abas para organizar melhor
    tab1, tab2, tab3 = st.tabs(["üìã Dados", "üìä Estat√≠sticas", "üìà Visualiza√ß√µes"])
    
    with tab1:
        st.subheader("Primeiras Linhas do Dataset")
        st.dataframe(df_ames.head(10), use_container_width=True)
        
        # Info sobre tipos de dados
        st.subheader("Informa√ß√µes sobre Vari√°veis")
        col1, col2 = st.columns(2)
        with col1:
            st.write("**Vari√°veis Num√©ricas:**")
            numeric_cols = df_ames.select_dtypes(include=np.number).columns.tolist()
            st.write(f"Total: {len(numeric_cols)}")
            st.write(numeric_cols[:10])  # Primeiras 10
            
        with col2:
            st.write("**Vari√°veis Categ√≥ricas:**")
            cat_cols = df_ames.select_dtypes(include='object').columns.tolist()
            st.write(f"Total: {len(cat_cols)}")
            st.write(cat_cols[:10])  # Primeiras 10
    
    with tab2:
        st.subheader("Estat√≠sticas Descritivas - Vari√°veis Num√©ricas")
        st.dataframe(df_ames.describe(include=np.number), use_container_width=True)
        
        # Estat√≠sticas das categ√≥ricas
        st.subheader("Estat√≠sticas - Vari√°veis Categ√≥ricas (Top 5 categorias)")
        cat_cols = df_ames.select_dtypes(include='object').columns
        for col in cat_cols[:5]:  # Primeiras 5 categ√≥ricas
            st.write(f"**{col}:**")
            st.write(df_ames[col].value_counts().head())
    
    with tab3:
        if 'SalePrice' in df_ames.columns:
            st.subheader("Distribui√ß√£o do Pre√ßo de Venda (SalePrice)")
            
            col1, col2 = st.columns(2)
            with col1:
                fig_hist = px.histogram(
                    df_ames, x='SalePrice', nbins=50,
                    title="Distribui√ß√£o Normal do Pre√ßo",
                    labels={'SalePrice': 'Pre√ßo de Venda ($)', 'count': 'Frequ√™ncia'}
                )
                st.plotly_chart(fig_hist, use_container_width=True)
            
            with col2:
                # Log do pre√ßo para melhor visualiza√ß√£o
                df_temp = df_ames.copy()
                df_temp['LogSalePrice'] = np.log(df_temp['SalePrice'])
                fig_log = px.histogram(
                    df_temp, x='LogSalePrice', nbins=50,
                    title="Distribui√ß√£o Log do Pre√ßo",
                    labels={'LogSalePrice': 'Log(Pre√ßo)', 'count': 'Frequ√™ncia'}
                )
                st.plotly_chart(fig_log, use_container_width=True)
        
        # Heatmap de correla√ß√£o
        st.subheader("Matriz de Correla√ß√£o (Top 15 Vari√°veis Num√©ricas)")
        numeric_cols = df_ames.select_dtypes(include=np.number).columns
        if len(numeric_cols) > 0:
            # Selecionar as 15 vari√°veis mais correlacionadas com SalePrice
            if 'SalePrice' in numeric_cols:
                corr_with_price = df_ames[numeric_cols].corr()['SalePrice'].abs().sort_values(ascending=False)
                top_cols = corr_with_price.head(15).index.tolist()
            else:
                top_cols = numeric_cols[:15].tolist()
            
            corr_matrix = df_ames[top_cols].corr()
            
            fig_corr = px.imshow(
                corr_matrix,
                title="Heatmap de Correla√ß√£o",
                color_continuous_scale="RdBu",
                aspect="auto",
                text_auto=".2f"
            )
            fig_corr.update_layout(height=600)
            st.plotly_chart(fig_corr, use_container_width=True)

# --- Se√ß√£o 2: An√°lise ANOVA ---
elif analysis_type == "üî¨ An√°lise ANOVA":
    st.header("üî¨ I. An√°lise Explorat√≥ria e Comparativa com ANOVA")
    st.markdown("""
    **Objetivo:** Investigar se existem diferen√ßas significativas no pre√ßo m√©dio de venda (`SalePrice`) 
    entre categorias de vari√°veis selecionadas, seguindo a metodologia da Tarefa 2.
    """)

    if 'SalePrice' not in df_ames.columns:
        st.error("‚ùå A coluna 'SalePrice' √© necess√°ria para ANOVA.")
        st.stop()

    # Configura√ß√µes da ANOVA na sidebar
    st.sidebar.markdown("### üî¨ Configura√ß√µes ANOVA")
    
    # Sele√ß√£o de vari√°veis categ√≥ricas
    all_cat_vars = []
    for col in df_ames.columns:
        if col != 'SalePrice':
            if df_ames[col].dtype == 'object' and df_ames[col].nunique() < 15 and df_ames[col].nunique() > 1:
                all_cat_vars.append(col)
            elif col in ['OverallQual', 'OverallCond'] and df_ames[col].nunique() < 15:
                all_cat_vars.append(col)

    # Vari√°veis sugeridas baseadas na tarefa
    suggested_vars = ['OverallQual', 'Neighborhood', 'CentralAir', 'KitchenQual', 'ExterQual', 'BsmtQual']
    default_vars = [var for var in suggested_vars if var in all_cat_vars][:3]

    selected_cat_vars = st.sidebar.multiselect(
        "Escolha 2-3 vari√°veis categ√≥ricas:",
        options=all_cat_vars,
        default=default_vars,
        help="Selecione vari√°veis como tipo de bairro, qualidade do acabamento, etc."
    )

    if not selected_cat_vars:
        st.warning("‚ö†Ô∏è Selecione pelo menos uma vari√°vel categ√≥rica para an√°lise.")
        st.stop()

    # Op√ß√µes de testes
    st.sidebar.markdown("### üß™ Op√ß√µes de Testes")
    show_assumptions = st.sidebar.checkbox("Verificar pressupostos ANOVA", value=True)
    show_robust_tests = st.sidebar.checkbox("Executar testes robustos", value=True)
    show_posthoc = st.sidebar.checkbox("Teste Post-hoc (Tukey)", value=True)

    # An√°lise para cada vari√°vel selecionada
    for i, cat_var in enumerate(selected_cat_vars):
        st.markdown(f"## {i+1}. An√°lise: {cat_var} vs. SalePrice")
        
        # Prepara√ß√£o dos dados
        anova_data = df_ames[['SalePrice', cat_var]].dropna()
        
        # Converter para string se necess√°rio
        if anova_data[cat_var].dtype != 'object':
            anova_data[cat_var] = anova_data[cat_var].astype(str)

        # Filtrar grupos com pelo menos 2 observa√ß√µes
        group_counts = anova_data[cat_var].value_counts()
        valid_groups = group_counts[group_counts >= 2].index
        anova_data = anova_data[anova_data[cat_var].isin(valid_groups)]

        if len(valid_groups) < 2:
            st.warning(f"‚ö†Ô∏è Grupos insuficientes para '{cat_var}'. Pulando an√°lise.")
            continue

        # Estat√≠sticas descritivas por grupo
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Boxplot interativo
            fig_box = px.box(
                anova_data, x=cat_var, y='SalePrice',
                title=f'Distribui√ß√£o do Pre√ßo por {cat_var}',
                color=cat_var,
                labels={'SalePrice': 'Pre√ßo de Venda ($)'}
            )
            fig_box.update_layout(showlegend=False, height=400)
            st.plotly_chart(fig_box, use_container_width=True)

        with col2:
            # Estat√≠sticas por grupo
            st.markdown("**Estat√≠sticas por Grupo:**")
            grupo_stats = anova_data.groupby(cat_var)['SalePrice'].agg(['count', 'mean', 'std']).round(2)
            st.dataframe(grupo_stats, use_container_width=True)

        # Teste ANOVA F
        st.markdown("### üìä Teste ANOVA (F-Test)")
        groups = [anova_data['SalePrice'][anova_data[cat_var] == val] for val in valid_groups]
        f_statistic, p_value_anova = stats.f_oneway(*groups)
        
        # Resultados em m√©tricas
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("F-Statistic", f"{f_statistic:.4f}")
        with col2:
            st.metric("p-valor", f"{p_value_anova:.4g}")
        with col3:
            is_significant = p_value_anova < alpha_global
            st.metric("Resultado", "‚úÖ Significativo" if is_significant else "‚ùå N√£o Significativo")

        # Interpreta√ß√£o
        if is_significant:
            st.success(f"""
            **‚úÖ Resultado Significativo (p = {p_value_anova:.4g} < {alpha_global})**
            
            H√° diferen√ßa estatisticamente significativa no pre√ßo m√©dio de venda entre as categorias de '{cat_var}'.
            Essa vari√°vel impacta significativamente na precifica√ß√£o dos im√≥veis.
            """)
        else:
            st.info(f"""
            **‚ÑπÔ∏è Resultado N√£o Significativo (p = {p_value_anova:.4g} ‚â• {alpha_global})**
            
            N√£o h√° evid√™ncia de diferen√ßa significativa no pre√ßo m√©dio entre as categorias de '{cat_var}'.
            """)

        # Verifica√ß√£o de pressupostos
        if show_assumptions:
            st.markdown("### üîç Verifica√ß√£o dos Pressupostos da ANOVA")
            
            # Ajustar modelo para an√°lise de res√≠duos
            model_ols = ols(f'SalePrice ~ C({cat_var})', data=anova_data).fit()
            residuals = model_ols.resid
            
            col1, col2 = st.columns(2)
            
            with col1:
                # 1. Teste de Normalidade
                st.markdown("**1. Normalidade dos Res√≠duos**")
                if len(residuals) <= 5000:
                    shapiro_stat, shapiro_p = stats.shapiro(residuals)
                    st.write(f"Shapiro-Wilk: W = {shapiro_stat:.4f}, p = {shapiro_p:.4g}")
                    if shapiro_p > alpha_global:
                        st.success("‚úÖ Res√≠duos s√£o normais (p > Œ±)")
                    else:
                        st.warning("‚ö†Ô∏è Res√≠duos N√ÉO s√£o normais (p ‚â§ Œ±)")
                else:
                    ks_stat, ks_p = stats.kstest(residuals, 'norm', args=(np.mean(residuals), np.std(residuals)))
                    st.write(f"Kolmogorov-Smirnov: D = {ks_stat:.4f}, p = {ks_p:.4g}")
                    if ks_p > alpha_global:
                        st.success("‚úÖ Res√≠duos s√£o normais (p > Œ±)")
                    else:
                        st.warning("‚ö†Ô∏è Res√≠duos N√ÉO s√£o normais (p ‚â§ Œ±)")

            with col2:
                # 2. Teste de Homocedasticidade
                st.markdown("**2. Homocedasticidade (Levene)**")
                levene_stat, levene_p = stats.levene(*groups)
                st.write(f"Levene: W = {levene_stat:.4f}, p = {levene_p:.4g}")
                if levene_p > alpha_global:
                    st.success("‚úÖ Vari√¢ncias homog√™neas (p > Œ±)")
                else:
                    st.warning("‚ö†Ô∏è Heterocedasticidade detectada (p ‚â§ Œ±)")

            # Q-Q Plot
            fig_qq, ax_qq = plt.subplots(figsize=(8, 5))
            sm.qqplot(residuals, line='s', ax=ax_qq, fit=True)
            ax_qq.set_title(f'Q-Q Plot dos Res√≠duos - {cat_var}')
            st.pyplot(fig_qq)
            plt.close(fig_qq)

        # Testes Robustos
        if show_robust_tests:
            st.markdown("### üõ°Ô∏è Testes N√£o-Param√©tricos (Robustos)")
            
            # Kruskal-Wallis
            kruskal_stat, kruskal_p = stats.kruskal(*groups)
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Kruskal-Wallis H", f"{kruskal_stat:.4f}")
            with col2:
                st.metric("p-valor KW", f"{kruskal_p:.4g}")
            
            if kruskal_p < alpha_global:
                st.success(f"‚úÖ Kruskal-Wallis: Diferen√ßa significativa nas medianas (p = {kruskal_p:.4g})")
            else:
                st.info(f"‚ÑπÔ∏è Kruskal-Wallis: Sem diferen√ßa significativa (p = {kruskal_p:.4g})")

        # Post-hoc Tukey
        if show_posthoc and is_significant:
            st.markdown("### üéØ Teste Post-hoc (Tukey HSD)")
            st.info("Executado apenas quando ANOVA √© significativa")
            
            try:
                tukey_results = pairwise_tukeyhsd(anova_data['SalePrice'], anova_data[cat_var], alpha=alpha_global)
                st.text(str(tukey_results))
                
                # Interpreta√ß√£o do Tukey
                tukey_df = pd.DataFrame(data=tukey_results._results_table.data[1:], columns=tukey_results._results_table.data[0])
                significant_pairs = tukey_df[tukey_df['reject'] == True]
                
                if len(significant_pairs) > 0:
                    st.success(f"‚úÖ {len(significant_pairs)} compara√ß√µes par a par s√£o significativas:")
                    for _, row in significant_pairs.iterrows():
                        st.write(f"‚Ä¢ **{row['group1']} vs {row['group2']}**: diferen√ßa = {row['meandiff']:.0f}")
                else:
                    st.info("‚ÑπÔ∏è Nenhuma compara√ß√£o par a par √© significativa ap√≥s corre√ß√£o.")
                    
            except Exception as e:
                st.error(f"Erro no teste Tukey: {e}")

        st.markdown("---")  # Separador entre vari√°veis

# --- Se√ß√£o 3: Regress√£o Linear ---
elif analysis_type == "üìà Regress√£o Linear":
    st.header("üìà II. Modelagem Preditiva com Regress√£o Linear")
    st.markdown("""
    **Objetivo:** Construir um modelo de regress√£o linear m√∫ltipla para prever o pre√ßo de venda (`SalePrice`) 
    seguindo as especifica√ß√µes da Tarefa 2.
    """)

    if 'SalePrice' not in df_ames.columns:
        st.error("‚ùå A coluna 'SalePrice' √© necess√°ria para Regress√£o.")
        st.stop()

    # Configura√ß√µes da Regress√£o na sidebar
    st.sidebar.markdown("### üìà Configura√ß√µes da Regress√£o")
    
    # Sele√ß√£o de vari√°veis
    numerical_predictors = df_ames.select_dtypes(include=np.number).columns.tolist()
    numerical_predictors = [col for col in numerical_predictors if col not in ['SalePrice', 'Order', 'PID']]
    
    categorical_predictors = df_ames.select_dtypes(include='object').columns.tolist()
    categorical_predictors = [col for col in categorical_predictors if df_ames[col].nunique() < 20]

    # Vari√°veis sugeridas baseadas na import√¢ncia para pre√ßos imobili√°rios
    suggested_num = ['GrLivArea', 'OverallQual', 'TotalBsmtSF', 'YearBuilt', 'GarageCars']
    suggested_cat = ['Neighborhood', 'CentralAir', 'KitchenQual', 'ExterQual']
    
    default_num = [var for var in suggested_num if var in numerical_predictors][:4]
    default_cat = [var for var in suggested_cat if var in categorical_predictors][:2]

    selected_numerical = st.sidebar.multiselect(
        "Vari√°veis Num√©ricas (4-6 total):",
        options=numerical_predictors,
        default=default_num,
        help="Escolha vari√°veis cont√≠nuas como √°rea, ano de constru√ß√£o, etc."
    )

    selected_categorical = st.sidebar.multiselect(
        "Vari√°veis Categ√≥ricas (1-2):",
        options=categorical_predictors,
        default=default_cat,
        help="Escolha vari√°veis categ√≥ricas (ser√£o convertidas em dummies)"
    )

    # Op√ß√µes de modelagem
    st.sidebar.markdown("### üîß Op√ß√µes de Modelagem")
    use_log_transform = st.sidebar.checkbox("Transforma√ß√£o Log-Log", value=True, 
                                          help="Aplica log na vari√°vel dependente e nas cont√≠nuas")
    include_constant = st.sidebar.checkbox("Incluir Intercepto", value=True)
    use_robust = st.sidebar.checkbox("Modelo Robusto (HC0)", value=False,
                                   help="Corre√ß√£o para heterocedasticidade")

    # Valida√ß√£o da sele√ß√£o
    total_vars = len(selected_numerical) + len(selected_categorical)
    if total_vars < 4 or total_vars > 6:
        st.warning(f"‚ö†Ô∏è Selecione entre 4-6 vari√°veis (atual: {total_vars})")
        st.stop()
    
    if len(selected_numerical) == 0:
        st.warning("‚ö†Ô∏è Selecione pelo menos uma vari√°vel cont√≠nua")
        st.stop()
    
    if len(selected_categorical) == 0:
        st.warning("‚ö†Ô∏è Selecione pelo menos uma vari√°vel categ√≥rica")
        st.stop()

    # Prepara√ß√£o dos dados
    X_vars = selected_numerical + selected_categorical
    reg_df = df_ames[['SalePrice'] + X_vars].copy().dropna()
    
    if reg_df.shape[0] < 50:
        st.error("‚ùå Dados insuficientes ap√≥s limpeza")
        st.stop()

    st.success(f"‚úÖ Dataset preparado: {reg_df.shape[0]} observa√ß√µes, {len(X_vars)} preditores")

    # Abas para organizar a an√°lise
    tab1, tab2, tab3, tab4 = st.tabs(["üîß Prepara√ß√£o", "üìä Modelo", "üîç Diagn√≥sticos", "üí° Interpreta√ß√£o"])

    with tab1:
        st.subheader("üîß Prepara√ß√£o dos Dados")
        
        # Mostrar correla√ß√µes com SalePrice
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Correla√ß√µes com SalePrice:**")
            correlations = reg_df[selected_numerical + ['SalePrice']].corr()['SalePrice'].sort_values(ascending=False)
            correlations = correlations.drop('SalePrice')  # Remove auto-correla√ß√£o
            st.dataframe(correlations.to_frame('Correla√ß√£o'), use_container_width=True)

        with col2:
            st.markdown("**Estat√≠sticas das Vari√°veis Categ√≥ricas:**")
            for cat_var in selected_categorical:
                st.write(f"**{cat_var}:**")
                st.write(f"Categorias √∫nicas: {reg_df[cat_var].nunique()}")
                st.write(reg_df[cat_var].value_counts().head(3))

        # Aplicar transforma√ß√µes
        y = reg_df['SalePrice'].copy()
        X = reg_df[X_vars].copy()

        if use_log_transform:
            st.markdown("**üîÑ Aplicando Transforma√ß√£o Log-Log**")
            y = np.log(y)
            
            # Log nas vari√°veis num√©ricas (evitando zeros)
            for col in selected_numerical:
                X[col] = np.log(X[col].replace(0, 1))
            
            st.info("‚úÖ Transforma√ß√£o logar√≠tmica aplicada em SalePrice e vari√°veis num√©ricas")

        # Criar vari√°veis dummy
        if selected_categorical:
            X_dummies = pd.get_dummies(X[selected_categorical], drop_first=True, dtype=float)
            X = pd.concat([X[selected_numerical], X_dummies], axis=1)
            st.info(f"‚úÖ Vari√°veis dummy criadas: {X_dummies.shape[1]} novas vari√°veis")

        # Adicionar constante
        if include_constant:
            X = sm.add_constant(X.astype(float))

        # Mostrar dados finais
        st.markdown("**üìã Dados Finais para Modelagem:**")
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"Vari√°vel dependente: {y.name} (transformada: {'Log' if use_log_transform else 'Original'})")
            st.write(f"Observa√ß√µes: {len(y)}")
        with col2:
            st.write(f"Preditores: {X.shape[1]}")
            st.write(f"Nomes: {list(X.columns)}")

    with tab2:
        st.subheader("üìä Ajuste do Modelo")
        
        try:
            # Ajustar modelo
            if use_robust:
                model = sm.OLS(y, X).fit(cov_type='HC0')
                st.info("üõ°Ô∏è Modelo robusto (HC0) para heterocedasticidade")
            else:
                model = sm.OLS(y, X).fit()
                st.info("üìä Modelo OLS padr√£o")

            # M√©tricas do modelo
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("R¬≤", f"{model.rsquared:.4f}")
            with col2:
                st.metric("R¬≤ Ajustado", f"{model.rsquared_adj:.4f}")
            with col3:
                # RMSE
                y_pred = model.predict(X)
                if use_log_transform:
                    # Converter de volta para escala original
                    y_actual_orig = np.exp(y)
                    y_pred_orig = np.exp(y_pred)
                    rmse = np.sqrt(mean_squared_error(y_actual_orig, y_pred_orig))
                    st.metric("RMSE", f"${rmse:,.0f}")
                else:
                    rmse = np.sqrt(mean_squared_error(y, y_pred))
                    st.metric("RMSE", f"${rmse:,.0f}")
            with col4:
                # MAE
                if use_log_transform:
                    mae = mean_absolute_error(y_actual_orig, y_pred_orig)
                    st.metric("MAE", f"${mae:,.0f}")
                else:
                    mae = mean_absolute_error(y, y_pred)
                    st.metric("MAE", f"${mae:,.0f}")

            # Sum√°rio completo
            st.markdown("**üìã Sum√°rio Completo do Modelo:**")
            st.text(str(model.summary()))

            # Signific√¢ncia das vari√°veis
            st.markdown("**üéØ Signific√¢ncia das Vari√°veis:**")
            coef_df = pd.DataFrame({
                'Vari√°vel': model.params.index,
                'Coeficiente': model.params.values,
                'Std Error': model.bse.values,
                't-statistic': model.tvalues.values,
                'p-valor': model.pvalues.values,
                'Significativo': model.pvalues.values < alpha_global
            })
            
            # Colorir significativas
            def highlight_significant(val):
                return 'background-color: lightgreen' if val else 'background-color: lightcoral'
            
            styled_df = coef_df.style.applymap(highlight_significant, subset=['Significativo'])
            st.dataframe(styled_df, use_container_width=True)

        except Exception as e:
            st.error(f"‚ùå Erro no ajuste do modelo: {e}")
            st.stop()

    with tab3:
        st.subheader("üîç Diagn√≥sticos dos Pressupostos")
        
        residuals = model.resid
        fitted_values = model.fittedvalues
        
        # 1. Linearidade e Homocedasticidade
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**1. Res√≠duos vs Valores Ajustados**")
            fig_res, ax_res = plt.subplots(figsize=(8, 6))
            ax_res.scatter(fitted_values, residuals, alpha=0.6)
            ax_res.axhline(0, color='red', linestyle='--')
            ax_res.set_xlabel('Valores Ajustados')
            ax_res.set_ylabel('Res√≠duos')
            ax_res.set_title('Res√≠duos vs Ajustados')
            st.pyplot(fig_res)
            plt.close(fig_res)
            st.caption("Ideal: pontos aleat√≥rios em torno de zero")

        with col2:
            st.markdown("**2. Q-Q Plot (Normalidade)**")
            fig_qq, ax_qq = plt.subplots(figsize=(8, 6))
            sm.qqplot(residuals, line='s', ax=ax_qq, fit=True)
            ax_qq.set_title('Q-Q Plot dos Res√≠duos')
            st.pyplot(fig_qq)
            plt.close(fig_qq)
            st.caption("Ideal: pontos pr√≥ximos √† linha diagonal")

        # 2. Testes estat√≠sticos
        st.markdown("**üß™ Testes dos Pressupostos:**")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # Normalidade (Shapiro-Wilk ou Kolmogorov-Smirnov)
            st.markdown("**Normalidade dos Res√≠duos:**")
            if len(residuals) <= 5000:
                shapiro_stat, shapiro_p = stats.shapiro(residuals)
                st.write(f"Shapiro-Wilk: {shapiro_p:.4g}")
                if shapiro_p > alpha_global:
                    st.success("‚úÖ Normal")
                else:
                    st.warning("‚ö†Ô∏è N√£o Normal")
            else:
                ks_stat, ks_p = stats.kstest(residuals, 'norm', args=(np.mean(residuals), np.std(residuals)))
                st.write(f"K-S Test: {ks_p:.4g}")
                if ks_p > alpha_global:
                    st.success("‚úÖ Normal")
                else:
                    st.warning("‚ö†Ô∏è N√£o Normal")

        with col2:
            # Homocedasticidade (Breusch-Pagan)
            st.markdown("**Homocedasticidade:**")
            try:
                X_bp = X.select_dtypes(include=np.number)
                bp_test = het_breuschpagan(residuals, X_bp)
                bp_p = bp_test[1]
                st.write(f"Breusch-Pagan: {bp_p:.4g}")
                if bp_p > alpha_global:
                    st.success("‚úÖ Homoced√°stico")
                else:
                    st.warning("‚ö†Ô∏è Heteroced√°stico")
            except:
                st.info("Teste BP n√£o dispon√≠vel")

        with col3:
            # Multicolinearidade (VIF)
            st.markdown("**Multicolinearidade (VIF):**")
            try:
                X_vif = X.drop(columns=['const']) if 'const' in X.columns else X
                X_vif = X_vif.select_dtypes(include=np.number)
                
                if X_vif.shape[1] > 1:
                    vif_values = []
                    for i in range(X_vif.shape[1]):
                        vif = variance_inflation_factor(X_vif.values, i)
                        vif_values.append(vif)
                    
                    max_vif = max(vif_values)
                    st.write(f"VIF M√°ximo: {max_vif:.2f}")
                    if max_vif < 10:
                        st.success("‚úÖ VIF < 10")
                    elif max_vif < 20:
                        st.warning("‚ö†Ô∏è VIF Moderado")
                    else:
                        st.error("‚ùå VIF Alto")
                        
                    # Mostrar VIF detalhado
                    vif_df = pd.DataFrame({
                        'Vari√°vel': X_vif.columns,
                        'VIF': vif_values
                    })
                    st.dataframe(vif_df, use_container_width=True)
                else:
                    st.info("VIF requer m√∫ltiplas vari√°veis")
            except Exception as e:
                st.error(f"Erro VIF: {e}")

    with tab4:
        st.subheader("üí° Interpreta√ß√£o e Recomenda√ß√µes")
        
        # Interpreta√ß√£o dos coeficientes
        st.markdown("**üìä Interpreta√ß√£o dos Coeficientes:**")
        
        interpretation_data = []
        for var in model.params.index:
            coef = model.params[var]
            p_val = model.pvalues[var]
            is_sig = p_val < alpha_global
            
            if var == 'const':
                if use_log_transform:
                    interp = f"Intercepto: exp({coef:.4f}) = {np.exp(coef):,.0f} (pre√ßo base)"
                else:
                    interp = f"Intercepto: ${coef:,.0f} (pre√ßo base)"
            else:
                if use_log_transform and var in selected_numerical:
                    # Interpreta√ß√£o elasticidade
                    elasticity = coef * 100
                    interp = f"Elasticidade: +1% em {var} ‚Üí {elasticity:+.2f}% no pre√ßo"
                elif var.startswith(tuple(selected_categorical)):
                    # Vari√°vel dummy
                    if use_log_transform:
                        pct_change = (np.exp(coef) - 1) * 100
                        interp = f"Dummy {var}: {pct_change:+.1f}% vs categoria base"
                    else:
                        interp = f"Dummy {var}: ${coef:+,.0f} vs categoria base"
                else:
                    # Vari√°vel num√©rica sem log
                    interp = f"+1 unidade em {var} ‚Üí ${coef:+,.0f} no pre√ßo"
            
            interpretation_data.append({
                'Vari√°vel': var,
                'Coeficiente': f"{coef:.4f}",
                'p-valor': f"{p_val:.4g}",
                'Significativo': "‚úÖ" if is_sig else "‚ùå",
                'Interpreta√ß√£o': interp
            })
        
        interp_df = pd.DataFrame(interpretation_data)
        st.dataframe(interp_df, use_container_width=True)
        
        # Recomenda√ß√µes pr√°ticas
        st.markdown("**üéØ Recomenda√ß√µes Pr√°ticas para Precifica√ß√£o:**")
        
        significant_vars = model.params[model.pvalues < alpha_global]
        significant_vars = significant_vars.drop('const', errors='ignore')
        
        if len(significant_vars) > 0:
            st.markdown("**Vari√°veis com maior impacto (significativas):**")
            
            # Ordenar por magnitude do impacto
            if use_log_transform:
                # Para log-log, usar elasticidade
                impacts = [(var, abs(coef)) for var, coef in significant_vars.items() if var in selected_numerical]
                impacts.extend([(var, abs(np.exp(coef) - 1)) for var, coef in significant_vars.items() if var not in selected_numerical])
            else:
                impacts = [(var, abs(coef)) for var, coef in significant_vars.items()]
            
            impacts.sort(key=lambda x: x[1], reverse=True)
            
            for i, (var, impact) in enumerate(impacts[:5], 1):
                coef = significant_vars[var]
                if var in selected_numerical and use_log_transform:
                    st.write(f"{i}. **{var}**: Elasticidade de {coef*100:.1f}% - Alta prioridade para valoriza√ß√£o")
                elif var.startswith(tuple(selected_categorical)):
                    if use_log_transform:
                        pct_effect = (np.exp(coef) - 1) * 100
                        st.write(f"{i}. **{var}**: {pct_effect:+.1f}% no pre√ßo - Caracter√≠stica importante")
                    else:
                        st.write(f"{i}. **{var}**: ${coef:+,.0f} no pre√ßo - Caracter√≠stica importante")
                else:
                    st.write(f"{i}. **{var}**: ${coef:+,.0f} por unidade - Impacto direto no valor")
        
        # Qualidade do modelo
        st.markdown("**üìà Qualidade do Modelo:**")
        
        col1, col2 = st.columns(2)
        with col1:
            r2_interpretation = ""
            if model.rsquared >= 0.8:
                r2_interpretation = "üåü Excelente poder explicativo"
            elif model.rsquared >= 0.6:
                r2_interpretation = "‚úÖ Bom poder explicativo"
            elif model.rsquared >= 0.4:
                r2_interpretation = "‚ö†Ô∏è Poder explicativo moderado"
            else:
                r2_interpretation = "‚ùå Baixo poder explicativo"
            
            st.write(f"**R¬≤ = {model.rsquared:.3f}** - {r2_interpretation}")
            st.write(f"O modelo explica {model.rsquared*100:.1f}% da varia√ß√£o nos pre√ßos")
        
        with col2:
            if use_log_transform:
                st.write(f"**RMSE = ${rmse:,.0f}**")
                st.write(f"**MAE = ${mae:,.0f}**")
                st.write("Erros em escala original (d√≥lares)")

# Rodap√©
st.sidebar.markdown("---")
st.sidebar.info("""
**üìö Sobre este Dashboard:**
- An√°lise completa do Ames Housing Dataset
- ANOVA para compara√ß√£o de grupos  
- Regress√£o Linear para predi√ß√£o de pre√ßos
- Implementado para Tarefa 2 - UnB/EPR
""")

# Informa√ß√µes t√©cnicas no final
if not df_ames.empty:
    with st.expander("‚ÑπÔ∏è Informa√ß√µes T√©cnicas"):
        st.markdown(f"""
        **Dataset:** Ames Housing Dataset  
        **Observa√ß√µes:** {df_ames.shape[0]:,}  
        **Vari√°veis:** {df_ames.shape[1]}  
        **Pre√ßo m√©dio:** {'${:,.0f}'.format(df_ames['SalePrice'].mean()) if 'SalePrice' in df_ames.columns else 'N/A'}  
        **N√≠vel de signific√¢ncia configurado:** {alpha_global}  
        
        **M√©todos implementados:**
        - ANOVA F-test com verifica√ß√£o de pressupostos
        - Testes n√£o-param√©tricos (Kruskal-Wallis)
        - Regress√£o Linear M√∫ltipla (OLS)
        - Transforma√ß√µes log-log para elasticidades
        - Diagn√≥sticos de res√≠duos completos
        - Corre√ß√£o robusta para heterocedasticidade
        """)
        
        st.markdown("**üë®‚Äçüè´ Professor:** Jo√£o Gabriel de Moraes Souza")
        st.markdown("**üè´ Institui√ß√£o:** UnB - Engenharia de Produ√ß√£o")
